{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d353d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fc5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_17332\\456756423.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Size_in_Mb  Content_Rating  Ad_Supported  In_App_Purchases  \\\n",
      "0         0        10.0               0             0                 0   \n",
      "1         1         2.9               0             1                 0   \n",
      "2         2         3.7               0             0                 0   \n",
      "3         3         1.8               0             1                 0   \n",
      "4         1         6.2               0             0                 0   \n",
      "\n",
      "   Transformed_Rating  Installs  Free  Rating_Count  Editors_Choice  \n",
      "0                   0        10     1             0               0  \n",
      "1                   4      5000     1            64               0  \n",
      "2                   0        50     1             0               0  \n",
      "3                   5        10     1             5               0  \n",
      "4                   0       100     1             0               0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to SQL Server\n",
    "conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"root\", database=\"GooglePlayStore\")\n",
    "\n",
    "# Fetch Data\n",
    "query = \"SELECT * FROM rating_pred\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "df = df.drop('id', axis=1)\n",
    "# Show first few rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3e34d",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b9d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237013, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d84119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame Shape: (1537013, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Filter out rows where Transformed_Rating is 0\n",
    "zero_rating_rows = df[df[\"Transformed_Rating\"] == 0]\n",
    "\n",
    "# Randomly sample 500,000 rows from the filtered DataFrame\n",
    "rows_to_drop = zero_rating_rows.sample(n=700000, random_state=42)\n",
    "\n",
    "# Drop these rows from the original DataFrame\n",
    "df = df.drop(rows_to_drop.index).reset_index(drop=True)\n",
    "\n",
    "# Check the new shape\n",
    "print(\"New DataFrame Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189adb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Size_in_Mb  Content_Rating  Ad_Supported  In_App_Purchases  \\\n",
      "0         1         2.9               0             1                 0   \n",
      "1         2         3.7               0             0                 0   \n",
      "2         3         1.8               0             1                 0   \n",
      "3         4        46.0               1             0                 1   \n",
      "4         5         2.5               0             1                 0   \n",
      "\n",
      "   Transformed_Rating  Installs  Free  Rating_Count  Editors_Choice  \n",
      "0                   4      5000     1            64               0  \n",
      "1                   0        50     1             0               0  \n",
      "2                   5        10     1             5               0  \n",
      "3                   0        50     1             0               0  \n",
      "4                   5      1000     1            12               0  \n",
      "Index(['Category', 'Size_in_Mb', 'Content_Rating', 'Ad_Supported',\n",
      "       'In_App_Purchases', 'Transformed_Rating', 'Installs', 'Free',\n",
      "       'Rating_Count', 'Editors_Choice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  \n",
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a74b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original Class Distribution: Counter({4: 561859, 5: 412277, 0: 346271, 3: 173693, 2: 38770, 1: 4143})\n",
      "New DataFrame Shape: (1537013, 10)\n",
      "ðŸ”¹ After SMOTETomek: Counter({0: 393291, 1: 388089, 2: 376311, 3: 364145, 5: 353763, 4: 343229})\n",
      "X shape: (2218828, 9), Y shape: (2218828,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load dataset\n",
    "X = df.drop(\"Transformed_Rating\", axis=1)  # Features\n",
    "Y = df[\"Transformed_Rating\"]  # Target variable\n",
    "\n",
    "# Original class distribution\n",
    "print(\"ðŸ”¹ Original Class Distribution:\", Counter(Y))\n",
    "# Check the new shape\n",
    "print(\"New DataFrame Shape:\", df.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.3, random_state=7,stratify=Y)\n",
    "\n",
    "# # Apply SMOTETomek (Combination)\n",
    "smote_tomek = SMOTETomek(random_state=7)\n",
    "X_train_resampled, Y_train_resampled = smote_tomek.fit_resample(X_train, Y_train)\n",
    "print(\"ðŸ”¹ After SMOTETomek:\", Counter(Y_train_resampled))\n",
    "\n",
    "# # Choose the final resampled data (you can pick any of the resampled data)\n",
    "# X = X_combined  \n",
    "# Y = y_combined  \n",
    "\n",
    "# # Ensure X and y have the same number of samples after resampling\n",
    "print(f\"X shape: {X_train_resampled.shape}, Y shape: {Y_train_resampled.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ec555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and Target\n",
    "# X = df.drop('Transformed_Rating', axis=1)\n",
    "# Y = df['Transformed_Rating'].astype(int)  # Ensure categorical target\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7, stratify=Y)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba272fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, random_state=7)\n",
    "hgbc.fit(X_train, Y_train)\n",
    "y_pred = hgbc.predict(X_test)\n",
    "hgbc_ac = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"HistGradientBoosting Classifier Accuracy:\", hgbc_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ff2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model Logistic Regression\n",
    "\n",
    "logreg_c=LogisticRegression(max_iter=500, random_state=7, class_weight='balanced')\n",
    "logreg_c.fit(X_train,Y_train)\n",
    "logreg_pred=logreg_c.predict(X_test)\n",
    "logreg_cm=confusion_matrix(Y_test,logreg_pred)\n",
    "logreg_ac=accuracy_score(Y_test, logreg_pred)\n",
    "print('LogisticRegression_accuracy:',logreg_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model RandomForest\n",
    "\n",
    "rdf_c=RandomForestClassifier(random_state=7)\n",
    "rdf_c.fit(X_train,Y_train)\n",
    "rdf_pred=rdf_c.predict(X_test)\n",
    "rdf_cm=confusion_matrix(Y_test,rdf_pred)\n",
    "rdf_ac=accuracy_score(rdf_pred,Y_test)\n",
    "print('RandomForest_Accuracy: ', rdf_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model DecisionTree Classifier\n",
    "\n",
    "dtree_c=DecisionTreeClassifier(random_state=7,criterion='entropy', max_depth = 10, min_samples_leaf = 2, min_samples_split = 5)\n",
    "dtree_c.fit(X_train,Y_train)\n",
    "dtree_pred=dtree_c.predict(X_test)\n",
    "dtree_cm=confusion_matrix(Y_test,dtree_pred)\n",
    "dtree_ac=accuracy_score(dtree_pred,Y_test)\n",
    "print('DecisionTreeClassifier_Accuracy: ',dtree_ac)\n",
    "\n",
    "with open(\"rating_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dtree_c, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b792da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model Naive Bayesian\n",
    "\n",
    "NB = BernoulliNB(binarize = 0.0)\n",
    "NB.fit(X_train,Y_train)\n",
    "y_pred = NB.predict(X_test)\n",
    "nb_ac=accuracy_score(Y_test, y_pred)\n",
    "print(\"Bernoulli Naive Bayes_Accuracy: \", nb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying AdaBoost Classifier\n",
    "abc = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "abc.fit(X_train, Y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "abc_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"AdaBoost Classifier Accuracy:\", abc_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying XGBoost Classifier\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=7, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, Y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"XGBoost Classifier Accuracy:\", xgb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bf60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightGBM classifier\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "lgb_model.fit(X_train, Y_train)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "lgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"LightGBM Classifier Accuracy:\", lgb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd32e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning CatBoost Classifier\n",
    "param_grid_catboost = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "catboost = CatBoostClassifier(verbose=0)\n",
    "grid_search_catboost = GridSearchCV(catboost, param_grid_catboost, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_catboost.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and score for CatBoost\n",
    "print(\"Best Parameters (CatBoost):\", grid_search_catboost.best_params_)\n",
    "print(\"Best Accuracy (CatBoost):\", grid_search_catboost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying Model CatBoost Model\n",
    "\n",
    "Cat_Boost = CatBoostClassifier(verbose = 300, n_estimators = 3500, learning_rate=0.1, depth=10,early_stopping_rounds=300)\n",
    "# Cat_Boost = CatBoostClassifier(verbose = 0)\n",
    "Cat_Boost.fit(X_train, Y_train)\n",
    "cb_ac=Cat_Boost.score(X_train, Y_train)\n",
    "print(\"CatBoost_Accuracy: \",cb_ac)\n",
    "\n",
    "with open(\"rating_model_one.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Cat_Boost, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b0a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.5333701\ttotal: 3.59s\tremaining: 59m 44s\n",
      "300:\tlearn: 0.9152899\ttotal: 19m 51s\tremaining: 46m 6s\n",
      "600:\tlearn: 0.8552416\ttotal: 39m\tremaining: 25m 54s\n",
      "900:\tlearn: 0.8172602\ttotal: 58m 35s\tremaining: 6m 26s\n",
      "999:\tlearn: 0.8072548\ttotal: 1h 4m 48s\tremaining: 0us\n",
      "CatBoost Accuracy:  0.6752871335678114\n",
      "F1 Score: 0.6254207514947179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Applying Model CatBoost Model\n",
    "\n",
    "Cat_Boost = CatBoostClassifier(verbose = 300, n_estimators=1000, learning_rate=0.2, depth=10,early_stopping_rounds=300)\n",
    "# Cat_Boost = CatBoostClassifier(verbose = 0)\n",
    "Cat_Boost.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "# Model Accuracy\n",
    "cb_ac = Cat_Boost.score(X_train_resampled, Y_train_resampled)\n",
    "print(\"CatBoost Accuracy: \", cb_ac)\n",
    "\n",
    "# Predictions\n",
    "y_pred = Cat_Boost.predict(X_test)\n",
    "\n",
    "# F1-Score Calculation\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")  # Use 'weighted' for multi-class\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "with open(\"finetuning_three.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Cat_Boost, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Train CatBoost model\n",
    "Cat_Boost = CatBoostClassifier(verbose=0)\n",
    "Cat_Boost.fit(X_train, Y_train)\n",
    "\n",
    "# Model Accuracy\n",
    "cb_ac = Cat_Boost.score(X_train, Y_train)\n",
    "print(\"CatBoost Accuracy: \", cb_ac)\n",
    "\n",
    "# Predictions\n",
    "y_pred = Cat_Boost.predict(X_test)\n",
    "\n",
    "# **F1-Score Calculation**\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")  # Use 'weighted' for multi-class\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# **ROC Curve Calculation**\n",
    "y_prob = Cat_Boost.predict_proba(X_test)  # Get probability estimates\n",
    "if len(set(Y_test)) == 2:  # Binary classification\n",
    "    fpr, tpr, _ = roc_curve(Y_test, y_prob[:, 1])  # Only second column for positive class\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve - CatBoost\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "else:\n",
    "    print(\"ROC curve is not applicable for multi-class classification.\")\n",
    "\n",
    "# Save the model\n",
    "with open(\"rating_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Cat_Boost, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36be7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
